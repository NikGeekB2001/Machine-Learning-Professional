{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e031a8",
   "metadata": {},
   "source": [
    "Возьмём датасет - Отзывы на фильмы с сайта IMDB (https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews), в которых для каждого отзыва поставлена семантическая оценка - \"позитивный\" или \"негативный\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f0b09",
   "metadata": {},
   "source": [
    "### Анализ тональности - процесс определения эмоциональной окраски текста, то есть является ли он положительным, отрицательным или нейтральным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0173c0",
   "metadata": {},
   "source": [
    "- >Можем выделить блоки, такие как:\n",
    "- Импорт необходимых библиотек и загрузка набора данных\n",
    "- Предварительная обработка текста, включая удаление знаков препинания, приведение к нижнему регистру, удаление стоп-слов и лемматизация\n",
    "- Векторизация текста, используя мешок слов или TF-IDF\n",
    "- Разделение данных на обучающую и тестовую выборки\n",
    "- Обучение и оценка различных моделей машинного обучения\n",
    "- Визуализация результатов, используя матрицу ошибок и кривые ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26142f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем библиотеку, если у кого не установлена\n",
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2639d0c",
   "metadata": {},
   "source": [
    "#### 1. Начальный импорт необходимых библиотек и загрузка набора данных, далее библиотеки будут отмечены в шаге кода ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2875b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import nltk # импорт модуля nltk, который содержит инструменты для работы с естественным языком\n",
    "from nltk.corpus import stopwords # импорт списка стоп-слов из модуля nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01694d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых модулей\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # импорт класса TfidfVectorizer из модуля sklearn.feature_extraction.text, который позволяет преобразовать текст в векторы с весами, основанными на частоте термов и обратной частоте документов\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression # импорт классов LinearRegression и LogisticRegression из модуля sklearn.linear_model, которые позволяют обучать линейные модели регрессии и классификации соответственно\n",
    "from sklearn.model_selection import train_test_split # импорт функции train_test_split из модуля sklearn.model_selection, которая позволяет разбить данные на обучающую и тестовую выборки\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, roc_curve, auc # импорт функций mean_squared_error, accuracy_score, confusion_matrix, roc_curve и auc из модуля sklearn.metrics, которые позволяют оценивать качество моделей по разным метрикам\n",
    "import matplotlib.pyplot as plt # импорт модуля matplotlib.pyplot под именем plt, который позволяет строить графики и визуализировать данные\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9fd871",
   "metadata": {},
   "source": [
    "#### 2. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90bd38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка набора данных IMDB\n",
    "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55adf357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выводим размерность объекта DataFrame\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e8d47b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вызываем метод value_counts() на столбце sentiment объекта DataFrame df\n",
    "# Этот метод возвращает серию, содержащую частоту каждого уникального значения в столбце\n",
    "# Результатом будет серия с индексом из значений столбца sentiment и значениями из их частот\n",
    "data.sentiment.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f06169",
   "metadata": {},
   "source": [
    "\"позитивные\" и \"негативные\" отзывы разделены на  25000 - поровну"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17ba1af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем уникальные значения столбца \"sentiment\" в датафрейме data\n",
    "# Это позволяет узнать, какие эмоции были выражены в текстах\n",
    "data[\"sentiment\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e1332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative', 'positive'}\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем столбец \"sentiment\" в датафрейме data в множество\n",
    "# Это позволяет убрать повторяющиеся значения и получить упорядоченный набор эмоций\n",
    "print(set(data[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c81547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "5  Probably my all-time favorite movie, a story o...  positive\n"
     ]
    }
   ],
   "source": [
    "# Выберем все примеры с положительным настроением\n",
    "positive_examples = data[data['sentiment'] == 'positive']\n",
    "\n",
    "# Выведем первые 5 примеров\n",
    "print(positive_examples.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ba3d2",
   "metadata": {},
   "source": [
    "#### 3. Предобработка данных\n",
    "Прежде, чем перейти к ML, текст необходимо предобработать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fb457",
   "metadata": {},
   "source": [
    "Предварительная обработка текста, включая удаление знаков препинания, приведение к нижнему регистру, удаление стоп-слов и лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2150da91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество стоп-слов: 179\n",
      "Первые 10 стоп-слов: ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kolin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Загружаем список стоп-слов для английского языка\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Выводим количество стоп-слов и первые 10 из них\n",
    "print(f\"Количество стоп-слов: {len(stop_words)}\")\n",
    "print(f\"Первые 10 стоп-слов: {stop_words[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a6ef6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', '...']\n"
     ]
    }
   ],
   "source": [
    "# Создаем токенизатор WordPunctTokenizer из библиотеки nltk\n",
    "word_tokenizer = nltk.WordPunctTokenizer()\n",
    "# Применяем токенизатор \n",
    "tokens = word_tokenizer.tokenize('One of the other reviewers has mentioned that ...')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fefc1461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  \\\n",
      "0  One of the other reviewers has mentioned that ...  positive   \n",
      "1  A wonderful little production. <br /><br />The...  positive   \n",
      "2  I thought this was a wonderful way to spend ti...  positive   \n",
      "3  Basically there's a family where a little boy ...  negative   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
      "\n",
      "                                              tokens  \n",
      "0  [One, of, the, other, reviewers, has, mentione...  \n",
      "1  [A, wonderful, little, production, ., <, br, /...  \n",
      "2  [I, thought, this, was, a, wonderful, way, to,...  \n",
      "3  [Basically, there, ', s, a, family, where, a, ...  \n",
      "4  [Petter, Mattei, ', s, \", Love, in, the, Time,...  \n"
     ]
    }
   ],
   "source": [
    "# Создаем токенизатор WordPunctTokenizer из библиотеки nltk\n",
    "word_tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "# Применяем токенизатор к каждому обзору в датасете\n",
    "data['tokens'] = data['review'].apply(word_tokenizer.tokenize)\n",
    "\n",
    "# Выводим первые 5 строк датасета для проверки\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8721fc",
   "metadata": {},
   "source": [
    "- Создаем функцию words_only, которая принимает текст, извлекает из него только слова на английском языке, приводит их к нижнему регистру и возвращает их в виде одной строки. \n",
    "- Затем используем функцию на примере строки 'To be, or not to be: that is the question!!! 2023 year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "810109e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be or not to be that is the question year\n"
     ]
    }
   ],
   "source": [
    "# Импортируем модуль re, который позволяет работать с регулярными выражениями\n",
    "import re\n",
    "\n",
    "# Создаем регулярное выражение, которое соответствует только буквам английского алфавита\n",
    "# Регулярное выражение состоит из двух частей: [A-Za-z] и [-]\n",
    "# Первая часть означает, что мы ищем любую букву в верхнем или нижнем регистре\n",
    "# Вторая часть означает, что мы также ищем дефис\n",
    "# Знак + означает, что мы ищем одну или более повторений предыдущего символа или группы символов\n",
    "regex = re.compile(r'[A-Za-z-]+')\n",
    "\n",
    "# Определяем функцию words_only, которая принимает текст и регулярное выражение в качестве аргументов\n",
    "# По умолчанию мы используем регулярное выражение, которое мы создали выше\n",
    "def words_only(text, regex=regex):\n",
    "    # Используем конструкцию try-except, чтобы обработать возможные ошибки\n",
    "    try:\n",
    "        # Используем метод findall, чтобы найти все совпадения регулярного выражения в тексте\n",
    "        # Этот метод возвращает список строк, которые соответствуют регулярному выражению\n",
    "        # Используем метод join, чтобы объединить элементы списка в одну строку, разделяя их пробелами\n",
    "        # Используем метод lower, чтобы привести все буквы к нижнему регистру\n",
    "        return \" \".join(regex.findall(text)).lower()\n",
    "    # Если произошла ошибка, возвращаем пустую строку\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# Пример использования функции\n",
    "# Передаем строку 'To be, or not to be: that is the question!!! 2024 year' в качестве аргумента функции words_only\n",
    "# Функция возвращает строку 'to be or not to be that is the question year', которую мы выводим на экран с помощью функции print\n",
    "print(words_only('To be, or not to be: that is the question!!! 2024 year'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ca3ef",
   "metadata": {},
   "source": [
    "Найдем стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fdc7f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 573398), (',', 544030), ('.', 467982), ('and', 309118), ('a', 309103), ('of', 285087), ('to', 263658), ('is', 214740), ('/', 202455), ('>', 202250), ('<', 202094), ('br', 201948), ('in', 173139), ('I', 163294), ('it', 151931), ('that', 137744), (\"'s\", 121768), ('this', 120442), ('was', 99090), ('The', 87819), ('as', 85000), ('with', 84743), ('movie', 83813), ('for', 82594), ('film', 75940), (')', 71268), ('(', 69585), ('but', 68864), (\"''\", 66435), (\"n't\", 65930), ('``', 65695), ('on', 64621), ('you', 61807), ('are', 59379), ('not', 57052), ('have', 56188), ('his', 54573), ('be', 52361), ('!', 49164), ('he', 48041), ('one', 47091), ('at', 43361), ('by', 42842), ('an', 41376), ('all', 41242), ('who', 40615), ('they', 38718), ('from', 38646), ('like', 37671), ('It', 35619), ('so', 34311), ('or', 34011), ('about', 33544), ('has', 33431), ('her', 33007), ('just', 32829), ('out', 32374), ('?', 32338), ('do', 31115), ('This', 29208), ('some', 28489), ('good', 27582), ('more', 27193), ('very', 26369), ('would', 26132), ('what', 25393), ('there', 24958), ('up', 24006), ('can', 23422), ('when', 23162), ('time', 22947), ('if', 22903), ('which', 22767), ('really', 22267), ('had', 22228), ('only', 22109), ('their', 22055), ('were', 21898), ('see', 21865), ('even', 21703), ('she', 21693), ('story', 21622), ('no', 21013), ('my', 20614), ('me', 20400), ('did', 20297), ('does', 19823), (\"'\", 19781), ('...', 19745), (':', 19414), ('-', 19294), ('than', 19122), ('much', 18455), ('been', 18206), ('could', 18198), ('get', 17823), ('into', 17726), ('will', 17298), ('other', 17291), ('we', 17085)]\n"
     ]
    }
   ],
   "source": [
    "# Импортируем модуль collections, который содержит полезные структуры данных\n",
    "from collections import Counter\n",
    "# Импортируем модуль nltk, который предоставляет инструменты для обработки текстов\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Определяем функцию get_most_common_words, которая принимает список текстов и число n в качестве аргументов\n",
    "def get_most_common_words(texts, n=100):\n",
    "    # Создаем пустой список all_words, в котором будем хранить все слова из текстов\n",
    "    all_words = []\n",
    "    # Проходимся по каждому тексту в списке texts\n",
    "    for text in texts:\n",
    "        # Используем функцию word_tokenize, чтобы разбить текст на отдельные слова\n",
    "        words = word_tokenize(text)\n",
    "        # Добавляем полученный список слов в список all_words с помощью метода extend\n",
    "        all_words.extend(words)\n",
    "    # Используем класс Counter, чтобы подсчитать, сколько раз каждое слово встречается в списке all_words\n",
    "    # Метод most_common возвращает список кортежей, содержащих слова и их частоты, отсортированный по убыванию частоты\n",
    "    # Аргумент n означает, сколько наиболее частых слов мы хотим получить\n",
    "    most_common_words = Counter(all_words).most_common(n)\n",
    "    # Возвращаем список most_common_words из функции\n",
    "    return most_common_words\n",
    "\n",
    "# Использование функции\n",
    "# Передаем столбец 'review' из датафрейма data в качестве аргумента функции get_most_common_words\n",
    "# Функция возвращает список из 100 наиболее частых слов и их частот, которые мы сохраняем в переменную most_common_words\n",
    "most_common_words = get_most_common_words(data['review'])\n",
    "# Выводим значение переменной most_common_words на экран с помощью функции print\n",
    "print(most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c111948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'I', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Импорт модуля string для работы со знаками пунктуации\n",
    "import string\n",
    "\n",
    "# Задаем список наиболее часто встречающихся слов\n",
    "most_common_words = [('the', 573398), (',', 544030), ('.', 467982), ('and', 309118), ('a', 309103), ('of', 285087), ('to', 263658), ('is', 214740), ('/', 202455), ('>', 202250), ('<', 202094), ('br', 201948), ('in', 173139), ('I', 163294), ('it', 151931), ('that', 137744), (\"'s\", 121768), ('this', 120442), ('was', 99090), ('The', 87819), ('as', 85000), ('with', 84743), ('movie', 83813), ('for', 82594), ('film', 75940), (')', 71268), ('(', 69585), ('but', 68864), (\"''\", 66435), (\"n't\", 65930), ('``', 65695), ('on', 64621), ('you', 61807), ('are', 59379), ('not', 57052), ('have', 56188), ('his', 54573), ('be', 52361), ('!', 49164), ('he', 48041), ('one', 47091), ('at', 43361), ('by', 42842), ('an', 41376), ('all', 41242), ('who', 40615), ('they', 38718), ('from', 38646), ('like', 37671), ('It', 35619), ('so', 34311), ('or', 34011), ('about', 33544), ('has', 33431), ('her', 33007), ('just', 32829), ('out', 32374), ('?', 32338), ('do', 31115), ('This', 29208), ('some', 28489), ('good', 27582), ('more', 27193), ('very', 26369), ('would', 26132), ('what', 25393), ('there', 24958), ('up', 24006), ('can', 23422), ('when', 23162), ('time', 22947), ('if', 22903), ('which', 22767), ('really', 22267), ('had', 22228), ('only', 22109), ('their', 22055), ('were', 21898), ('see', 21865), ('even', 21703), ('she', 21693), ('story', 21622), ('no', 21013), ('my', 20614), ('me', 20400), ('did', 20297), ('does', 19823), (\"'\", 19781), ('...', 19745), (':', 19414), ('-', 19294), ('than', 19122), ('much', 18455), ('been', 18206), ('could', 18198), ('get', 17823), ('into', 17726), ('will', 17298), ('other', 17291), ('we', 17085)]\n",
    "\n",
    "# Создаем список стоп-слов из 10 самых встречающихся слов, исключая знаки пунктуации\n",
    "stop_words = [word for word, _ in most_common_words if word not in string.punctuation][:10]\n",
    "\n",
    "print(stop_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ec4b5",
   "metadata": {},
   "source": [
    "Расширим список стоп-слов, словами, которые являются стоп-словами в данной задаче. Удаляем знаки пунктуации и токенизируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08b009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kolin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Импортируем модуль re, который позволяет работать с регулярными выражениями\n",
    "import re\n",
    "# Импортируем модуль nltk, который предоставляет инструменты для обработки текстов\n",
    "import nltk\n",
    "# Импортируем подмодуль stopwords из модуля nltk.corpus, который содержит списки стоп-слов для разных языков\n",
    "from nltk.corpus import stopwords\n",
    "# Импортируем класс WordPunctTokenizer из модуля nltk.tokenize, который позволяет разбивать текст на слова с учетом пунктуации\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "# Импортируем модуль tqdm, который позволяет отображать прогресс выполнения циклов\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Создаем регулярное выражение, которое соответствует только буквам английского алфавита\n",
    "# Регулярное выражение состоит из двух частей: [A-Za-z] и [-]\n",
    "# Первая часть означает, что мы ищем любую букву в верхнем или нижнем регистре\n",
    "# Вторая часть означает, что мы также ищем дефис\n",
    "# Знак + означает, что мы ищем одну или более повторений предыдущего символа или группы символов\n",
    "regex = re.compile(r'[A-Za-z-]+')\n",
    "\n",
    "# Определяем функцию words_only, которая принимает текст и регулярное выражение в качестве аргументов\n",
    "# По умолчанию мы используем регулярное выражение, которое мы создали выше\n",
    "def words_only(text, regex=regex):\n",
    "    # Используем конструкцию try-except, чтобы обработать возможные ошибки\n",
    "    try:\n",
    "        # Используем метод findall, чтобы найти все совпадения регулярного выражения в тексте\n",
    "        # Этот метод возвращает список строк, которые соответствуют регулярному выражению\n",
    "        # Используем метод join, чтобы объединить элементы списка в одну строку, разделяя их пробелами\n",
    "        # Используем метод lower, чтобы привести все буквы к нижнему регистру\n",
    "        return \" \".join(regex.findall(text)).lower()\n",
    "    # Если произошла ошибка, возвращаем пустую строку\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# Загружаем список стоп-слов для английского языка с помощью функции download из модуля nltk\n",
    "nltk.download('stopwords')\n",
    "# Получаем список стоп-слов для английского языка с помощью функции words из подмодуля stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Расширим список стоп-слов, словами, которые являются стоп-словами в данной задаче\n",
    "# Это слова, которые не несут смысловой нагрузки или часто встречаются в текстах\n",
    "add_stop_words = ['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'I', 'it']\n",
    "\n",
    "# Объединяем два списка стоп-слов в один с помощью оператора +\n",
    "all_stop_words = stop_words + add_stop_words\n",
    "\n",
    "# Создаем объект токенизатора с помощью класса WordPunctTokenizer\n",
    "word_tokenizer = WordPunctTokenizer()\n",
    "\n",
    "# Определяем функцию process_data, которая принимает датафрейм data в качестве аргумента\n",
    "def process_data(data):\n",
    "    # Создаем пустой список texts, в котором будем хранить предобработанные тексты\n",
    "    texts = []\n",
    "\n",
    "    # Поочередно проходим по всем обзорам в столбце 'review' в датафрейме data\n",
    "    # Используем функцию tqdm, чтобы отображать прогресс выполнения цикла\n",
    "    for item in tqdm(data['review']):\n",
    "\n",
    "        # Используем функцию words_only, чтобы оставить только слова в обзоре\n",
    "        text_lower = words_only(item)\n",
    "        # Используем метод tokenize, чтобы разбить текст на слова с учетом пунктуации\n",
    "        tokens     = word_tokenizer.tokenize(text_lower)\n",
    "\n",
    "        # Удаляем пунктуацию и стоп-слова из списка слов\n",
    "        # Используем генератор списка, чтобы создать новый список, содержащий только те слова, которые не входят в список all_stop_words и не являются числами\n",
    "        tokens = [word for word in tokens if (word not in all_stop_words and not word.isnumeric())]\n",
    "\n",
    "        # Добавляем полученный список слов в список texts с помощью метода append\n",
    "        texts.append(tokens)\n",
    "\n",
    "    # Возвращаем список texts из функции\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828aba1",
   "metadata": {},
   "source": [
    "Создаем функцию process_data, которая принимает DataFrame data, применяет функцию words_only к столбцу 'review' для извлечения только слов, затем токенизирует текст и удаляет стоп-слова и числа. Результат сохраняется в новом списке texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f7e5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 50000/50000 [11:04<00:00, 75.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Если data - это DataFrame pandas:\n",
    "# .tolist() - это метод серии pandas, который преобразует серию в список.\n",
    "y = data['sentiment'].tolist()\n",
    "\n",
    "# Если data - это список словарей:\n",
    "# y = [item['sentiment'] for item in data]\n",
    "\n",
    "# Запускаем предобработку\n",
    "texts = process_data(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a6ecad",
   "metadata": {},
   "source": [
    "Описание:\n",
    "  > - y = y = data['sentiment'].tolist() Это генератор списка, который создает новый список y, содержащий значения 'sentiment' из датафрейма data. Это предполагает, что data - это DataFrame, где 'sentiment' - это одно из полей. В контексте анализа тональности текста, 'sentiment' обычно обозначает метку класса (например, \"положительный\" или \"отрицательный\").\n",
    "\n",
    "  > - texts = process_data(data): Это вызов функции process_data, которая, предобрабатывает данные, включая очистку текста, удаление стоп-слов и возможно другие шаги. Результат этой функции (предположительно список предобработанных текстов) сохраняется в переменной texts.\n",
    "  > - В общем, мы подготавливаем данные для дальнейшего использования в модели машинного обучения, извлекая метки классов и предобрабатывая текстовые данные.\n",
    "  > - Далее вызываем функцию process_data, передавая ей в качестве аргумента data. \n",
    "  > - Функция process_data выполняет предобработку данных, включая, возможно, очистку текста, удаление стоп-слов, токенизацию и другие шаги. Результат работы функции (список предобработанных текстов) сохраняется в переменной texts.\n",
    "  > - В итоге у нас есть два списка: y, содержащий метки классов, и texts, содержащий предобработанные тексты. Эти данные теперь можно использовать для обучения модели машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321b0b8",
   "metadata": {},
   "source": [
    "Теперь каждый пример представлен списком слов. Причем все слова с маленькой буквы. Пунктуацию и стоп-слова мы удалили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8d083d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  positive\n",
      "Tokens:  ['wonderful', 'little', 'production', 'filming', 'technique']\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "i = 1\n",
    "print(\"Label: \", y[i])\n",
    "print(\"Tokens: \", texts[i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a3c73",
   "metadata": {},
   "source": [
    "Пояснение:\n",
    "- i = 1: Задает значение переменной i равным 1. Это значение будет использоваться как индекс для извлечения элементов из списков y и texts.\n",
    "- print(\"Label: \", y[i]): Выводит на экран строку \"Label: \" и элемент из списка y с индексом i. В данном случае, поскольку i равно 1, будет выведен второй элемент списка y (индексация в Python начинается с 0). Это метка класса для второго обзора в датасете.\n",
    "- print(\"Tokens: \", texts[i][:5]): Выводит на экран строку \"Tokens: \" и первые пять элементов из списка texts с индексом i. Это первые пять токенов (слов или символов) после предобработки.\n",
    "- В общем, этот код просто показывает, как выглядит предобработанный текст и соответствующая ему метка класса в датасете.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124f7e2",
   "metadata": {},
   "source": [
    "#### 4. Нормализация слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87c9e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# инициализируем объект стеммер\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc4363",
   "metadata": {},
   "source": [
    "- Код инициализирует стеммер Snowball из библиотеки NLTK (Natural Language Toolkit) для английского языка.\n",
    "\n",
    "- Двойные кавычки вокруг \"english\" используются для указания аргумента функции или метода. В данном случае, \"english\" - это аргумент, который передается в конструктор SnowballStemmer. Этот аргумент указывает, что стеммер будет работать с английским языком.\n",
    "\n",
    "- Стеммер - это инструмент, используемый в обработке естественного языка для упрощения слов до их корневой формы (или \"леммы\"). Например, стеммер может преобразовать слова \"running\", \"runs\", \"ran\" и \"runner\" в \"run\". Это может быть полезно при анализе текста, поскольку это уменьшает размерность данных и делает его менее сложным для моделей машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f74a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: wonderful, After: wonder\n",
      "Before: little, After: littl\n",
      "Before: production, After: product\n",
      "Before: filming, After: film\n",
      "Before: technique, After: techniqu\n",
      "Before: unassuming, After: unassum\n",
      "Before: -, After: -\n",
      "Before: old, After: old\n",
      "Before: -, After: -\n",
      "Before: time, After: time\n"
     ]
    }
   ],
   "source": [
    "# примеры стемминга\n",
    "i = 1\n",
    "for aword in texts[i][:10]:\n",
    "    aword_stem = stemmer.stem(aword)\n",
    "    print(\"Before: %s, After: %s\" % (aword, aword_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af8f2dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\t This is an extension to the (ML for) Natural Language Processing course \n",
      "Stemmed text:\t this is an extens to the (ml for) natur languag process cours \n"
     ]
    }
   ],
   "source": [
    "text = 'This is an extension to the (ML for) Natural Language Processing course '\n",
    "stemmed_text = ' '.join([stemmer.stem(x) for x in text.split(' ')])\n",
    "print('Original text:\\t',text)\n",
    "print('Stemmed text:\\t',stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "834d32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем стемминг ко всем текстам\n",
    "# Стемминг - это процесс приведения слов к их основе или корню\n",
    "# Например, слова \"программирование\", \"программист\" и \"программа\" имеют общий корень \"программ\"\n",
    "# Стемминг может помочь уменьшить размер словаря и улучшить качество анализа текстов\n",
    "# Для стемминга мы используем объект stemmer, который должен быть определен заранее\n",
    "\n",
    "# Проходимся по всем текстам в списке texts с помощью цикла for\n",
    "# Используем функцию range, чтобы получить индексы текстов от 0 до длины списка texts\n",
    "for i in range(len(texts)):\n",
    "    # Для каждого текста применяем стемминг к каждому слову в тексте\n",
    "    # Используем генератор списка, чтобы создать новый список, содержащий основы слов\n",
    "    # Используем метод stem, чтобы получить основу каждого слова\n",
    "    text_stemmed = [stemmer.stem(x) for x in texts[i]]\n",
    "    # Объединяем все основы слов в одну строку через пробел\n",
    "    # Используем метод join, чтобы соединить элементы списка в одну строку\n",
    "    texts[i] = ' '.join(text_stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd1b258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для инфо\n",
    "# Удаляем символы новой строки из всех текстов\n",
    "#texts = [text.replace('\\n', '') for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2b8d8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  positive\n",
      "Text: \n",
      " wonder littl product film techniqu unassum - old - time - bbc fashion give comfort sometim discomfort sens realism entir piec actor extrem well chosen - michael sheen got polari voic pat truli see seamless edit guid refer william diari entri well worth watch terrif written perform piec master product one great master comedi life realism realli come home littl thing fantasi guard rather use tradit dream techniqu remain solid disappear play knowledg sens particular scene concern orton halliwel set particular flat halliwel mural decor everi surfac terribl well done\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на пример\n",
    "i = 1\n",
    "print(\"Label: \",   y[i])\n",
    "# \"Text: \\n\" - Это строка, которую мы хотите вывести. \n",
    "# \\n - это специальный символ, который создает новую строку, то есть переносит курсор на следующую строку.\n",
    "# texts[i] - Это элемент списка texts на позиции i. \n",
    "# i - это индекс элемента, который мы хотим вывести. \n",
    "# Индексация в Python начинается с 0, поэтому texts[0] вернет первый элемент списка, texts[1] - второй и т.д.\n",
    "print(\"Text: \\n\",  texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839d266",
   "metadata": {},
   "source": [
    "#### 5. Разбьём собранные данные на train/test, отложив 20-30% наблюдений для тестирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5ca81",
   "metadata": {},
   "source": [
    "Теоритическая справка\n",
    "Мы разбиваем собранные данные на обучающий и тестовый наборы, отложив 20-30% наблюдений для тестирования.\n",
    "Это позволит оценить, насколько хорошо наша модель будет работать на новых данных, которые она ранее не видела.\n",
    "\n",
    "Важно отметить, что порядок этих шагов может немного варьироваться в зависимости от конкретной задачи и предпочтений аналитика. Например, некоторые могут предпочесть сначала разделить данные на обучающий и тестовый наборы, а затем провести предварительную обработку текста отдельно для каждого набора. Это может помочь предотвратить утечку данных из тестового набора в обучающий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb67e0b",
   "metadata": {},
   "source": [
    "Лейблы у нас также закодированы словами. Для корректной работы алгорима конвертируем их в числа (`'negative', 'positive'`):\n",
    "\n",
    "    negative = -1\n",
    "    positive = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec3382b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для кодирования лейблов\n",
    "def label2num(y):\n",
    "    if y == 'positive':\n",
    "        return 1\n",
    "    if y == 'negative':\n",
    "        return -1\n",
    "    \n",
    "\n",
    "encoded_y = [label2num(yy) for yy in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ad9a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как вариант можно сделать так как ниже\n",
    "\n",
    "# Импортируем класс OrdinalEncoder из модуля sklearn.preprocessing\n",
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Определяем функцию для кодирования меток\n",
    "# def label2num(y):\n",
    "#    if y == 'positive':\n",
    "#        return 1\n",
    "#    if y == 'negative':\n",
    "#        return -1\n",
    "\n",
    "# Создаем список меток\n",
    "# y = ['positive', 'negative']\n",
    "\n",
    "# Применяем функцию label2num к каждой метке в списке y\n",
    "# Используем генератор списка, чтобы создать новый список, содержащий числовые метки\n",
    "# encoded_y = [label2num(yy) for yy in y]\n",
    "\n",
    "# Создаем объект ordinalencoder с параметром dtype=int\n",
    "# ordinalencoder = OrdinalEncoder(dtype=int)\n",
    "\n",
    "# Вызываем метод fit_transform на объекте ordinalencoder, передав ему список меток в виде двумерной матрицы\n",
    "# Для этого мы используем метод reshape из модуля numpy\n",
    "# import numpy as np\n",
    "# ordinal_y = ordinalencoder.fit_transform(np.array(encoded_y).reshape(-1, 1))\n",
    "\n",
    "# Выводим закодированные метки на экран\n",
    "# print(ordinal_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24043c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем функцию train_test_split из модуля sklearn.model_selection, который предоставляет инструменты для выбора \n",
    "# и разбиения данных\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Используем функцию train_test_split, чтобы разделить наши данные на обучающую и тестовую выборки\n",
    "# Передаем в качестве аргументов список текстов texts, список закодированных меток encoded_y, размер тестовой выборки test_size,\n",
    "# случайное состояние random_state и параметр стратификации stratify\n",
    "# Функция возвращает четыре массива: train_texts, test_texts, train_y, test_y, которые мы сохраняем в соответствующие переменные\n",
    "train_texts, test_texts, train_y, test_y = train_test_split(texts, encoded_y, test_size=0.2, random_state=42, stratify = y)\n",
    "# Разберем подробнее, что делает каждый аргумент функции train_test_split\n",
    "# texts - это список текстов, которые мы хотим использовать для обучения и тестирования нашей модели\n",
    "# encoded_y - это список меток, которые соответствуют текстам, например, положительный или отрицательный отзыв\n",
    "# test_size - это доля данных, которую мы хотим отвести для тестовой выборки, в нашем случае это 0.2, то есть 20%\n",
    "# random_state - это параметр, который контролирует случайность разбиения данных, если мы хотим воспроизводить результаты, \n",
    "# мы можем задать конкретное число, в нашем случае это 42\n",
    "# stratify - это параметр, который позволяет сохранить пропорцию меток в обучающей и тестовой выборках, \n",
    "# в нашем случае мы передаем список y, который содержит исходные метки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee25fe",
   "metadata": {},
   "source": [
    "#### 6. Применим tf-idf преобразование для текстового описания.\n",
    "- Используя как отдельные токены, так и биграммы, отсеиваем стоп-слова, а также слова, которые встречаются слишком редко или слишком часто (параметры min/max_df), и конечно не забудем убрать l2 регуляризацию, которая по умолчанию включена."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f9a43",
   "metadata": {},
   "source": [
    "Теоритическая справка:\n",
    "- Стемминг - это процесс, при котором от слов отбрасываются окончания и суффиксы, чтобы оставить только основу слова.\n",
    "- Мы применяем TF-IDF преобразование к нашим текстовым данным, чтобы получить векторы признаков для каждого документа. \n",
    "- TF-IDF - это мера, которая отражает важность слова в документе в коллекции документов. \n",
    "- Мы используем класс TfidfVectorizer из модуля sklearn.feature_extraction.text, который позволяет преобразовать коллекцию текстов в матрицу TF-IDF признаков.\n",
    "- TF-IDF - это аббревиатура от английских слов term frequency и inverse document frequency, что означает частота слова и обратная частота документа. Это статистическая мера, которая используется для оценки важности слова в контексте документа, являющегося частью коллекции документов или корпуса. TF-IDF высокий, если слово часто встречается в документе, но редко в других документах, что означает, что оно характеризует документ. TF-IDF низкий, если слово часто встречается во многих документах, что означает, что оно не специфично для документа. TF-IDF может использоваться для извлечения ключевых слов из текстов или для векторизации текстов для машинного обучения.\n",
    "\n",
    "Для вычисления TF-IDF, вам нужно знать две величины: TF и IDF.\n",
    "\n",
    "TF (term frequency) - это отношение числа вхождений некоторого слова к общему числу слов документа. Таким образом, оценивается важность слова в пределах отдельного документа. Формула для TF выглядит так:\n",
    "\n",
    "$$TF(t, d) = \\frac{n_t}{N}$$\n",
    "\n",
    "где $t$ - это слово, $d$ - это документ, $n_t$ - это число вхождений слова $t$ в документ $d$, а $N$ - это общее число слов в документе $d$.\n",
    "\n",
    "IDF (inverse document frequency) - это инверсия частоты, с которой некоторое слово встречается в документах коллекции. Основоположником данной концепции является Карен Спарк Джонс . Учёт IDF уменьшает вес широкоупотребительных слов. Для каждого уникального слова в пределах конкретной коллекции документов существует только одно значение IDF. Формула для IDF выглядит так:\n",
    "\n",
    "$$IDF(t, D) = \\log \\frac{|D|}{| \\{ d_i \\in D \\mid t \\in d_i \\} |}$$\n",
    "\n",
    "где $t$ - это слово, $D$ - это коллекция документов, $|D|$ - это число документов в коллекции, а $| \\{ d_i \\in D \\mid t \\in d_i \\} |$ - это число документов из коллекции $D$, в которых встречается слово $t$.\n",
    "\n",
    "Таким образом, мера TF-IDF является произведением двух сомножителей:\n",
    "\n",
    "$$TFIDF(t, d, D) = TF(t, d) \\times IDF(t, D)$$\n",
    "\n",
    "Большой вес в TF-IDF получат слова с высокой частотой в пределах конкретного документа и с низкой частотой употреблений в других документах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c33c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['act', 'actor', 'bad', 'charact', 'come', 'end', 'film', 'good',\n",
       "       'great', 'know'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортируем класс TfidfVectorizer из модуля sklearn.feature_extraction.text, который позволяет преобразовать коллекцию текстов\n",
    "# в матрицу TF-IDF признаков\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Создаем объект vectorizer с нужными параметрами\n",
    "# ngram_range=(1, 2) означает, что мы используем как отдельные токены, так и биграммы, то есть пары соседних слов, \n",
    "# чтобы уловить контекст\n",
    "# stop_words='english' означает, что мы отсеиваем стоп-слова на английском языке, которые не несут смысловой нагрузки\n",
    "# min_df=0.2 и max_df=0.8 означают, что мы отсеиваем слова, которые встречаются менее чем в 20% или более чем в 80% документов,\n",
    "# чтобы оставить только релевантные слова\n",
    "# norm=None означает, что мы не применяем l2 регуляризацию к векторам TF-IDF, которая по умолчанию включена в TF-IDF\n",
    "# векторизатор, чтобы не штрафовать слова с большими значениями TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', min_df=0.2, max_df=0.8, norm=None)\n",
    "\n",
    "# Вызываем метод fit на объекте vectorizer, передав ему список обучающих текстов train_texts\n",
    "# Этот метод извлекает слова и биграммы из текстов и вычисляет их IDF значения\n",
    "# Затем он сохраняет полученный словарь слов и их IDF в атрибуте vocabulary_ объекта vectorizer\n",
    "vectorizer.fit(train_texts)\n",
    "\n",
    "# Вызываем метод get_feature_names_out на объекте vectorizer, чтобы получить список слов и биграмм в словаре, отсортированный \n",
    "# по алфавиту\n",
    "# Затем мы берем первые 10 элементов этого списка, чтобы увидеть топ-10 слов и биграмм по алфавиту\n",
    "vectorizer.get_feature_names_out()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92fc1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем TF-IDF на train, а затем применяем к train и test\n",
    "# TF-IDF - это мера, которая отражает важность слова в документе в коллекции документов\n",
    "# TF (term frequency) - это частота слова в документе, а IDF (inverse document frequency) - это обратная частота документов,\n",
    "# содержащих слово в коллекции\n",
    "# TF-IDF высокий, если слово часто встречается в документе, но редко в других документах, что означает, что оно характеризует \n",
    "# документ\n",
    "# TF-IDF низкий, если слово часто встречается во многих документах, что означает, что оно не специфично для документа\n",
    "# TF-IDF может использоваться для извлечения ключевых слов из текстов или для векторизации текстов \n",
    "\n",
    "# Используем объект vectorizer, который мы создали ранее с помощью класса TfidfVectorizer\n",
    "# Вызываем метод fit_transform на объекте vectorizer, передав ему список обучающих текстов train_texts\n",
    "# Этот метод извлекает слова из текстов и вычисляет их IDF значения, а затем преобразует тексты в векторы TF-IDF\n",
    "# Возвращаем матрицу TF-IDF признаков для обучающих текстов и сохраняем ее в переменную train_X\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Вызываем метод transform на объекте vectorizer, передав ему список тестовых текстов test_texts\n",
    "# Этот метод преобразует тексты в векторы TF-IDF, используя уже известные IDF значения из обучающих текстов\n",
    "# Возвращаем матрицу TF-IDF признаков для тестовых текстов и сохраняем ее в переменную test_X\n",
    "test_X  = vectorizer.transform(test_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82b5d9",
   "metadata": {},
   "source": [
    "Теоритическая справка:\n",
    "- Стемминг - это процесс, при котором от слов отбрасываются окончания и суффиксы, чтобы оставить только основу слова.\n",
    "- Мы применяем TF-IDF преобразование к нашим текстовым данным, чтобы получить векторы признаков для каждого документа. \n",
    "- TF-IDF - это мера, которая отражает важность слова в документе в коллекции документов. \n",
    "- Мы используем класс TfidfVectorizer из модуля sklearn.feature_extraction.text, который позволяет преобразовать коллекцию текстов в матрицу TF-IDF признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cae6e32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 2.48790922,\n",
       "         1.69402254, 4.57784091, 0.        , 0.        , 0.        ,\n",
       "         1.43134652, 0.        , 2.47986111, 0.        , 2.1942125 ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         2.58184775],\n",
       "        [0.        , 0.        , 0.        , 0.        , 2.5641311 ,\n",
       "         0.        , 0.        , 1.95246118, 0.        , 2.48790922,\n",
       "         0.        , 2.28892045, 0.        , 0.        , 0.        ,\n",
       "         4.29403957, 0.        , 2.47986111, 2.57590725, 2.1942125 ,\n",
       "         2.49345924, 2.32165585, 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.88463539, 0.        , 2.00371355, 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример\n",
    "train_X.todense()[:2] # посмотрим на первые 2 строки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6a9af7",
   "metadata": {},
   "source": [
    "- В датасете целевая переменная непрерывная (например, среднее число просмотров в день), то воспользуемся линейной регрессией, если дискретная (положительный/отрицательный отзыв), то логистической.\n",
    "- В нашем случае дискретная величина\n",
    "- Построем регрессию с настройкой параметра регуляризации, оценим качество при помощи соответствующих задаче метрик."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d8db1",
   "metadata": {},
   "source": [
    "#### 7. Применяем логическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28157475",
   "metadata": {},
   "source": [
    "- Логическая регрессия - это метод машинного обучения, который позволяет предсказывать вероятность принадлежности объекта к одному из двух классов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdc4af",
   "metadata": {},
   "source": [
    "Обоснование:\n",
    "- Обучаем два раза в TF-IDF и в логистической регрессии. Одного раза не достаточно, потому что TF-IDF и логистическая регрессия решают разные задачи. \n",
    "- TF-IDF преобразует текстовые данные в векторы признаков, которые отражают важность слов в документах.\n",
    "- Логистическая регрессия обучает модель, которая предсказывает вероятность принадлежности документа к одному из двух классов, например, положительный или отрицательный отзыв.\n",
    "- Таким образом, TF-IDF подготавливает данные для логистической регрессии, а логистическая регрессия обучает модель на этих данных. Оба шага необходимы для построения эффективной модели машинного обучения на текстовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44e38233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель логистической регрессии на векторах TF-IDF\n",
    "# Логистическая регрессия - это метод машинного обучения, который позволяет предсказывать вероятность принадлежности объекта\n",
    "# к одному из двух классов, например, положительный или отрицательный отзыв\n",
    "# Логистическая регрессия строит линейную границу решения между классами и применяет логистическую функцию к линейной комбинации\n",
    "# признаков, чтобы получить вероятность принадлежности к положительному классу\n",
    "# Логистическая регрессия также использует регуляризацию, чтобы предотвратить переобучение модели, то есть слишком сильную\n",
    "# подгонку под обучающие данные\n",
    "\n",
    "# Импортируем класс LogisticRegression из модуля sklearn.linear_model, который позволяет создавать и обучать модели логистической регрессии\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9eff11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Регуляризация добавляет штраф к функции потерь модели, который зависит от величины весов признаков\n",
    "# Регуляризация может быть l1 или l2, в зависимости от того, какой нормы весов мы используем для штрафа\n",
    "# l1 регуляризация уменьшает некоторые веса признаков до нуля, тем самым делая модель более разреженной и отбирая наиболее \n",
    "# важные признаки\n",
    "# l2 регуляризация уменьшает все веса признаков, но не до нуля, тем самым делая модель более гладкой и предотвращая слишком \n",
    "# большие значения весов\n",
    "# Сила регуляризации контролируется параметром C, который является обратным значением коэффициента регуляризации\n",
    "# Чем меньше C, тем сильнее регуляризация, и наоборот\n",
    "# Подбор оптимального значения C можно делать с помощью кросс-валидации, то есть разбиения обучающих данных на несколько\n",
    "# частей и проверки качества модели на каждой из них\n",
    "# Создаем объект model с помощью класса LogisticRegression из модуля sklearn.linear_model\n",
    "# Указываем параметры, например, C=1.0, чтобы задать среднюю силу регуляризации\n",
    "# penalty=\"l2\", чтобы задать тип регуляризации\n",
    "# random_state=42, чтобы зафиксировать случайное состояние модели и получать воспроизводимые результаты\n",
    "model = LogisticRegression(C=1.0, penalty=\"l2\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d77ad7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем model на векторах TF-IDF и метках обучающей выборки с помощью метода fit\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "410c0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказываем метки тестовой выборки с помощью метода predict\n",
    "# Сохраняем список предсказанных меток в переменную pred_y\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01c76c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцениваем качество модели с помощью различных метрик\n",
    "# Метрики качества - это численные показатели, которые отражают, насколько хорошо модель справляется с задачей\n",
    "# Для задачи бинарной классификации, как в нашем случае, мы можем использовать следующие метрики:\n",
    "# Точность (accuracy) - это доля правильно предсказанных меток от общего числа меток\n",
    "# Матрица ошибок (confusion matrix) - это таблица, которая показывает, сколько объектов каждого класса было правильно \n",
    "# или неправильно предсказано моделью\n",
    "# Площадь под кривой ROC (ROC AUC) - это мера, которая отражает, насколько хорошо модель разделяет классы, \n",
    "# основываясь на вероятностях, которые она выдает\n",
    "# ROC кривая - это график, который показывает зависимость доли верно классифицированных положительных объектов (TPR)\n",
    "# от доли неверно классифицированных отрицательных объектов (FPR) при изменении порога вероятности, \n",
    "# по которому мы относим объект к положительному классу\n",
    "# Площадь под кривой ROC равна 1, если модель идеально разделяет классы, и равна 0.5, если модель не лучше случайного угадывания\n",
    "\n",
    "# Импортируем функции accuracy_score, confusion_matrix и roc_auc_score из модуля sklearn.metrics, который предоставляет \n",
    "# инструменты для оценки качества моделей\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5da419b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6849\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем точность модели с помощью функции accuracy_score\n",
    "# Передаем в качестве аргументов список истинных меток для тестовых данных и список предсказанных меток\n",
    "# Функция возвращает значение точности в диапазоне от 0 до 1\n",
    "accuracy = accuracy_score(test_y, pred_y)\n",
    "\n",
    "# Выводим значение точности на экран\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6a5cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3275 1725]\n",
      " [1426 3574]]\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем матрицу ошибок с помощью функции confusion_matrix\n",
    "# Передаем в качестве аргументов список истинных меток для тестовых данных и список предсказанных меток\n",
    "# Функция возвращает матрицу размера 2x2, где элементы по диагонали - это количество верно предсказанных объектов каждого класса,\n",
    "# а элементы вне диагонали - это количество неверно предсказанных объектов\n",
    "# Матрица имеет следующий вид:\n",
    "# [[TN, FP],\n",
    "#  [FN, TP]]\n",
    "# где TN - количество верно предсказанных отрицательных объектов, FP - количество неверно предсказанных положительных объектов,\n",
    "# FN - количество неверно предсказанных отрицательных объектов, TP - количество верно предсказанных положительных объектов\n",
    "conf_matrix = confusion_matrix(test_y, pred_y)\n",
    "\n",
    "# Выводим матрицу ошибок на экран\n",
    "print(f\"Confusion matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec8eefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем площадь под кривой ROC с помощью функции roc_auc_score\n",
    "# Передаем в качестве аргументов список истинных меток для тестовых данных и список вероятностей принадлежности \n",
    "# к положительному классу, которые можно получить с помощью метода predict_proba объекта model\n",
    "# Функция возвращает значение площади под кривой ROC в диапазоне от 0 до 1\n",
    "roc_auc = roc_auc_score(test_y, model.predict_proba(test_X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "148f40d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.75189222\n"
     ]
    }
   ],
   "source": [
    "# Выводим значение площади под кривой ROC на экран\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3bbdb",
   "metadata": {},
   "source": [
    "####  8. Визуализируем получившиеся коэффициенты регрессии (возьмем топ-50 слов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "040c14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем коэффициенты регрессии, которые отражают важность признаков для модели\n",
    "# Коэффициенты регрессии - это веса, которые модель присваивает каждому признаку, чтобы получить линейную комбинацию признаков\n",
    "# Чем больше по модулю коэффициент регрессии, тем больше влияние признака на предсказание модели\n",
    "# Знак коэффициента регрессии показывает, как признак влияет на вероятность принадлежности к положительному классу: \n",
    "# положительный знак означает, что признак увеличивает вероятность, а отрицательный знак - что уменьшает\n",
    "\n",
    "# Получаем список коэффициентов регрессии с помощью атрибута coef_ объекта model\n",
    "# Атрибут coef_ возвращает массив размера 1xN, где N - количество признаков\n",
    "# Преобразуем массив в одномерный список с помощью метода flatten\n",
    "coefs = model.coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "714880f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список слов, соответствующих признакам, с помощью метода get_feature_names_out объекта vectorizer\n",
    "# Метод get_feature_names_out возвращает список слов в словаре, отсортированный по алфавиту\n",
    "words = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e705a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем датафрейм с двумя столбцами: word - слово, coef - коэффициент регрессии\n",
    "# Используем функцию pd.DataFrame, передавая в качестве аргументов словарь с именами столбцов и списками значений\n",
    "df = pd.DataFrame({\"word\": words, \"coef\": coefs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aaae3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сортируем датафрейм по модулю коэффициента регрессии в убывающем порядке, чтобы получить топ-50 самых важных слов для модели\n",
    "# Используем метод sort_values, передавая в качестве аргументов имя столбца, по которому сортируем, и параметр ascending=False,\n",
    "# чтобы сортировать в убывающем порядке\n",
    "# Используем метод abs, чтобы применить модуль к столбцу coef\n",
    "# Используем метод head, чтобы взять первые 50 строк датафрейма\n",
    "df = df.sort_values(by='coef', key=abs, ascending=False).head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4a26b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toп 50 признаков:\n",
      "       word      coef\n",
      "0       act -0.098941\n",
      "1     actor -0.057233\n",
      "2       bad -0.383062\n",
      "3   charact -0.014226\n",
      "4      come  0.011513\n",
      "5       end -0.007804\n",
      "6      film  0.021687\n",
      "7      good  0.079371\n",
      "8     great  0.293388\n",
      "9      know -0.000778\n",
      "10     like -0.032909\n",
      "11     look -0.094273\n",
      "12     love  0.181848\n",
      "13     make -0.043262\n",
      "14     mani  0.074989\n",
      "15     movi -0.041379\n",
      "16    peopl  0.005574\n",
      "17     play  0.080175\n",
      "18     plot -0.131914\n",
      "19   realli -0.008951\n",
      "20      say -0.035772\n",
      "21    scene -0.019067\n",
      "22     seen  0.051394\n",
      "23    stori  0.039014\n",
      "24    thing -0.054572\n",
      "25    think  0.008523\n",
      "26     time  0.038194\n",
      "27     want -0.051280\n",
      "28    watch -0.022794\n",
      "29      way  0.041737\n",
      "30     work  0.048527\n"
     ]
    }
   ],
   "source": [
    "# Выводим первые 50 строк датафрейма на экран, чтобы увидеть топ-50 самых важных признаков для модели\n",
    "# Используем метод head для получения первых n строк датафрейма\n",
    "# Передаем в качестве аргумента число 50\n",
    "print(f\"Toп 50 признаков:\\n{df.head(50)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57eb02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем коэффициенты регрессии с помощью графика\n",
    "# Используем библиотеку matplotlib.pyplot для построения графика\n",
    "# Импортируем библиотеку с помощью команды import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5dde8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем горизонтальный столбчатый график, который показывает коэффициенты регрессии для топ-50 признаков\n",
    "# Используем функцию barh для создания графика\n",
    "# Передаем в качестве аргументов столбец word датафрейма df, который содержит названия признаков, и столбец coef, \n",
    "# который содержит значения коэффициентов регрессии\n",
    "# Параметр color позволяет задать цвет столбцов в зависимости от знака коэффициента: зеленый для положительных и \n",
    "# красный для отрицательных\n",
    "# Параметр edgecolor позволяет задать цвет границ столбцов\n",
    "plt.barh(df[\"word\"].head(50), df[\"coef\"].head(50), color=[\"green\" if x > 0 else \"red\" for x in df[\"coef\"].head(50)], edgecolor=\"black\")\n",
    "\n",
    "# Добавляем заголовок графика с помощью функции title\n",
    "plt.title(\"Коэффициенты логистической регрессии для топ-50 признаков\")\n",
    "\n",
    "# Добавляем подписи осей с помощью функций xlabel и ylabel\n",
    "plt.xlabel(\"Коэффициент\")\n",
    "plt.ylabel(\"Признаки\")\n",
    "\n",
    "# Показываем график\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81186b66",
   "metadata": {},
   "source": [
    "<h6 style= 'color: blue'>  Вывод по графику </h6> \n",
    "\n",
    "- График показывает, какие слова имеют наибольшее по модулю влияние на предсказание модели, и какой знак у этого влияния. Зеленые столбцы соответствуют словам, которые увеличивают вероятность принадлежности к положительному классу, а красные столбцы - словам, которые уменьшают эту вероятность.\n",
    "- Самое влиятельное слово по модулю - это “bad”, которое имеет отрицательный коэффициент -0.383062. Это означает, что если отзыв содержит это слово, то вероятность того, что он положительный, сильно снижается. Это логично, так как слово “bad” обычно используется для выражения негативного отношения к фильму.\n",
    "- Самое влиятельное слово с положительным знаком - это “great”, которое имеет коэффициент 0.293388. Это означает, что если отзыв содержит это слово, то вероятность того, что он положительный, сильно повышается. Это тоже логично, так как слово “great” обычно используется для выражения положительного отношения к фильму.\n",
    "- В топ-50 признаков входят также слова “love”, “plot”, “act”, “look” и “actor”, которые имеют большой по модулю коэффициент. Это означает, что эти слова тоже сильно влияют на предсказание модели, но в разных направлениях. Слова “love”, “play”, “good” и “mani” имеют положительное влияние, \n",
    "- а слова “plot”, “act”, “look” и “actor” - отрицательное. Это может быть связано с тем, что эти слова часто используются для оценки разных аспектов фильма, таких как сюжет, актерская игра, внешний вид и т.д., и могут иметь разный окрас в зависимости от контекста и тональности отзыва.\n",
    "- В топ-50 признаков также входят слова, которые имеют маленький по модулю коэффициент, например, “know”, “end”, “realli” и т.д. Это означает, что эти слова слабо влияют на предсказание модели, и могут быть не очень информативными для задачи классификации. Это может быть связано с тем, что эти слова часто используются в разных контекстах и не несут сильной эмоциональной окраски. От которых можно избавиться в последствии при новом обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1e894",
   "metadata": {},
   "source": [
    "<h6 style= 'color: blue'> Общий вывод </h6>\n",
    "\n",
    "- Результат логистической регрессии для задачи бинарной классификации текстовых отзывов на фильмы. \n",
    "- Модель предсказала, является ли отзыв положительным или отрицательным, на основе слов, которые в нем содержатся. \n",
    "- Мы использовали различные метрики качества, чтобы оценить, насколько хорошо модель справляется с задачей:\n",
    "- Точность (accuracy) - это доля правильно предсказанных меток от общего числа меток. Модель имеет точность 0.6849, что означает, что она правильно предсказывает 68.49% отзывов. Это неплохой результат, но не идеальный. Это может быть связано с тем, что модель не учитывает контекст, тональность или сарказм в отзывах, а также с тем, что некоторые отзывы могут быть неоднозначными или смешанными.\n",
    "- Площадь под кривой ROC (ROC AUC) - это мера, которая отражает, насколько хорошо модель разделяет классы, основываясь на вероятностях, которые она выдает. \n",
    "- ROC кривая - это график, который показывает зависимость доли верно классифицированных положительных объектов (TPR) от доли неверно классифицированных отрицательных объектов (FPR) при изменении порога вероятности, по которому мы относим объект к положительному классу. \n",
    "- Площадь под кривой ROC равна 1, если модель идеально разделяет классы, и равна 0.5, если модель не лучше случайного угадывания. Модель имеет площадь под кривой ROC 0.7519, что означает, что она достаточно хорошо разделяет классы, но не идеально. \n",
    "- Топ 50 признаков - это список слов, которые имеют наибольший по модулю коэффициент регрессии. Коэффициент регрессии - это вес, который модель присваивает каждому слову, чтобы получить линейную комбинацию слов. Чем больше по модулю коэффициент регрессии, тем больше влияние слова на предсказание модели. \n",
    "- Из графика мы можем сделать следующий вывод:\n",
    "- Модель улавливает некоторые общие слова, которые часто используются для выражения положительного или отрицательного отношения к фильму, но не учитывает более специфические или необычные слова, которые также могут быть важными.\n",
    "- Наша модель не учитывает контекст, тональность или сарказм в отзывах, а также не учитывает различия в сложности и длине отзывов, а также не учитывает противоречивые или неявные сигналы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86e88f",
   "metadata": {},
   "source": [
    "#### Возможные улучшения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19700f49",
   "metadata": {},
   "source": [
    "- Модель может быть улучшена, если мы используем другие типы векторизации текста, которые учитывают не только частоту слов, но и их важность, контекст и порядок, а также если мы используем другие модели или комбинируем несколько моделей в одну.\n",
    "- Точность - это одна из метрик качества, которая показывает, какая доля объектов была правильно предсказана моделью. Однако, точность не всегда является лучшей метрикой для оценки модели, особенно если данные несбалансированы, то есть один класс значительно превосходит другой по количеству объектов. В таком случае, модель может игнорировать меньший класс и предсказывать только больший класс, что приведет к высокой точности, но низкому качеству.\n",
    "- Для того, чтобы увеличить точность и другие метрики качества, нам нужно улучшить модель. Это можно сделать разными способами, например:\n",
    "- Подобрать оптимальные гиперпараметры модели, такие как коэффициент регуляризации, который контролирует сложность модели и предотвращает переобучение.\n",
    "- Для этого мы можем использовать функции GridSearchCV или RandomizedSearchCV из модуля sklearn.model_selection, которые позволяют перебирать разные значения гиперпараметров и выбирать лучшие по заданной метрике качества.\n",
    "- Преобразовать или отобрать признаки, которые используете для обучения модели. Некоторые признаки могут быть бесполезными или шумными для модели, поэтому их можно удалить или заменить на другие.\n",
    "- Использовать другую модель или комбинировать несколько моделей в одну. \n",
    "- Логистическая регрессия - это одна из простых и популярных моделей для бинарной классификации, но она может быть неэффективной для сложных или нелинейных данных. \n",
    "- В таком случае, мы можете попробовать другие модели, такие как деревья решений, случайный лес, градиентный бустинг, нейронные сети и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea6f3bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogisticRegression_model']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сериализовать объект\n",
    "import joblib\n",
    "joblib.dump(model, 'LogisticRegression_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad1b26",
   "metadata": {},
   "source": [
    "Спасибо за внимание!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
